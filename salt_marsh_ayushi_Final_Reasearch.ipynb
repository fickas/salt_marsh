{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fickas/salt_marsh/blob/main/salt_marsh_ayushi_Final_Reasearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification for salt marshes for Low,Mid and High Tides for RGB Images\n",
        "\n"
      ],
      "metadata": {
        "id": "L7kAqDWBSbTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Libraries to Import"
      ],
      "metadata": {
        "id": "yA6MC2piUzRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Code from Github for ease of usage."
      ],
      "metadata": {
        "id": "hUkRFTWDb0_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "github_name = 'ayushi0916'\n",
        "repo_name = 'ImageClassification_UAS'\n",
        "source_file = 'library.py'\n",
        "url = f'https://raw.githubusercontent.com/{github_name}/{repo_name}/main/{source_file}'\n",
        "!rm $source_file\n",
        "!wget $url\n",
        "%run -i $source_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO9w09qkacEi",
        "outputId": "2718a079-b34f-4d6e-af25-72b38f402598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-14 14:08:04--  https://raw.githubusercontent.com/ayushi0916/ImageClassification_UAS/main/library.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10800 (11K) [text/plain]\n",
            "Saving to: ‘library.py’\n",
            "\n",
            "\rlibrary.py            0%[                    ]       0  --.-KB/s               \rlibrary.py          100%[===================>]  10.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-14 14:08:04 (88.3 MB/s) - ‘library.py’ saved [10800/10800]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mouting google drive"
      ],
      "metadata": {
        "id": "4sVLeR47byKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xqxz72u5bxgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a9054c-08a9-432b-9631-69bf2b66c7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to first set up the data-set to be readable.\n",
        "\n",
        "*   Here the **folder_path_add** is the link to the image folder in the UAS Data Collection folder of the site that you want to classify the images of.\n",
        "*   Here the **output_folder_add** is the link to the new folder in the drive created to store the readable images.\n",
        "\n"
      ],
      "metadata": {
        "id": "p0TeYhatnMwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_add = \"\""
      ],
      "metadata": {
        "id": "vVKbvPBdL_k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder_add = \"\""
      ],
      "metadata": {
        "id": "S2M7p8C8ME9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RGB_Image_To_Readable(folder_path_add,output_folder_add)"
      ],
      "metadata": {
        "id": "diUsOZ2pnMKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once the images are converted to readable format the data-sets are created with minimum 20 images each in the folders classified as Regular,Irregular and Other.This step is already done and the folder is shared."
      ],
      "metadata": {
        "id": "qbTW1hRFogh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to the folder of the data-set with the data from Old Town Hill,Essex Bay and North River\n",
        "\n",
        "Links:\n",
        "input_folder_1 = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Regular_RGB_New'\n",
        "\n",
        "input_folder_2 = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Irregular_RGB_New'\n",
        "\n",
        "input_folder_3 = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Other_RGB_New'"
      ],
      "metadata": {
        "id": "TQwiXvcqpvXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As 20 images for each classification for training is too less we augment the data by using the below function.\n",
        "\n",
        "Links of the output folders are as below:\n",
        "\n",
        "  output_dir_regular = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Album_RGB_New/Regular'\n",
        "\n",
        "  output_dir_irregular = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Album_RGB_New/Irregular'\n",
        "\n",
        "  output_dir_other = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Album_RGB_New/Other'"
      ],
      "metadata": {
        "id": "RAPT1PEbqiBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder_1_link=\"\"\n",
        "input_folder_2_link=\"\"\n",
        "input_folder_3_link=\"\"\n",
        "output_dir1_link=\"\"\n",
        "output_dir2_link=\"\"\n",
        "output_dir3_link=\"\""
      ],
      "metadata": {
        "id": "hmx0s_8WMjPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Augment_data(input_folder_1_link,input_folder_2_link,input_folder_3_link,output_dir1_link,output_dir2_link,output_dir3_link)"
      ],
      "metadata": {
        "id": "8kT_9q5mptUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross-verifying the number of images saved in Regular, Irregular and Other"
      ],
      "metadata": {
        "id": "sf1NIlq4EQOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_augmentation(output_dir1_link,output_dir2_link,output_dir3_link)"
      ],
      "metadata": {
        "id": "uCGM7nTvEMDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99fb4dc-0e5b-490e-f681-be80109df9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in augmented folder: 208\n",
            "Number of images in augmented folder: 208\n",
            "Number of images in augmented folder: 208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Inception Size"
      ],
      "metadata": {
        "id": "2saygbM8FA3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_size = (299,299)"
      ],
      "metadata": {
        "id": "ZraN2Vj1Ei4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Created a extract_features function with input as the directory path to attain a vector with\n",
        "\n",
        "\n",
        "\n",
        "*   We first define the InceptionV3 model\n",
        "*   Labels are got from the folder names in the main directory\n",
        "\n",
        "\n",
        "*   Then we loop through each label which joins the label name with directory path to get label path.\n",
        "*  Once the label path is got then images in the folder are listed and then loaded\n",
        "\n",
        "\n",
        "*   Once the image is loaded its resized to be sent to the inceptionV3 model.\n",
        "*  It is converted to a NumPy array using img_to_array\n",
        "\n",
        "\n",
        "*  To add dimension to the array we use np.expand_dims\n",
        "*  To preprocess the input we use preprocess_input\n",
        "\n",
        "\n",
        "*  Once the prediction on the image is made we flatten out the output using flatten().\n",
        "*  We then add the extracted features and label to a dict\n",
        "\n",
        "\n",
        "\n",
        "*   Return Dict\n"
      ],
      "metadata": {
        "id": "u_ZLIuyXFKGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dirpath below is the path where the augmented data lies."
      ],
      "metadata": {
        "id": "WWEXySEmGnyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirpath = '/content/drive/MyDrive/RGB_15JuneMICA_OTH/Album_RGB_New'"
      ],
      "metadata": {
        "id": "F8AZd-BYIYYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dict=extract_features(dirpath)"
      ],
      "metadata": {
        "id": "LNarsESUFEG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost\n",
        "\n",
        "*   We first extract the features and the labels got from the inceptionV3 model.\n",
        "*   Then using the label Encoder encode the labels to numericals.\n",
        "\n",
        "\n",
        "*   Splitting the features and labels into train and test.\n",
        "*   Converting the train and test data into the DMatrix format which is optimized for XGBoost training\n",
        "\n",
        "\n",
        "*   Defining the model parameters\n",
        "*   Training the model\n",
        "\n",
        "\n",
        "*   Evaluating and printing the accuracy score of the model."
      ],
      "metadata": {
        "id": "89uamLxBIcqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Please replace the folder_path variable with the path where you stored the augmented data"
      ],
      "metadata": {
        "id": "PN1hwJP_sJZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert feature dictionary attained from the above function extract_features() to numpy arrays as below\n",
        "features = np.array([f[0] for f in feature_dict.values()])\n",
        "labels = np.array([f[1] for f in feature_dict.values()])\n",
        "print(labels)\n",
        "\n",
        "# Get the image file names\n",
        "image_names = list(feature_dict.keys())\n",
        "\n",
        "# Extract the folder names from the image file names\n",
        "folder_path = '' # replace with your Google Drive folder path of augmented data\n",
        "\n",
        "image_folders = [os.path.split(os.path.dirname(os.path.join(root, image_name)))[-1] for image_name in image_names for root, dirs, files in os.walk(folder_path) if image_name in files]\n",
        "\n",
        "# Create a list of image names with the folder names included\n",
        "image_names_with_folders = [os.path.join(folder, os.path.basename(image_name)) for folder, image_name in zip(image_folders, image_names)]\n",
        "\n",
        "# Convert the string labels to numerical labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "print(labels)\n",
        "\n",
        "#0-Other 2- Regular 1-Irregular\n",
        "print(len(features))\n",
        "print(len(labels))\n",
        "print(len(image_names_with_folders))\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_features, test_features, train_labels, test_labels, train_image_names, test_image_names = train_test_split(features, labels, image_names_with_folders, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Convert the data into DMatrix format, which is optimized for XGBoost training\n",
        "d_matrix_train = xgb.DMatrix(train_features, label=train_labels)\n",
        "d_matrix_test = xgb.DMatrix(test_features, label=test_labels)\n",
        "\n",
        "# Define the XGBoost parameters\n",
        "params = {\n",
        "    'n_estimators':30,\n",
        "    'num_class': 3, # change to the number of classes in your dataset\n",
        "    'seed': 42,\n",
        "    'eta': 0.2, # reduce the learning rate to mitigate overfitting\n",
        "    'max_depth': 4, # limit the maximum tree depth to reduce overfitting\n",
        "    'min_child_weight': 1, # Controls the minimum number of samples required in a child node to keep splitting it\n",
        "    'subsample': 0.8, # Controls the fraction of the training instances used for each tree\n",
        "    'colsample_bytree': 0.8, # Controls the fraction of the features used for each tree\n",
        "    'reg_alpha': 0, # L1 regularization term on the weights\n",
        "    'reg_lambda': 1, # L2 regularization term on the weights\n",
        "    'objective': 'multi:softmax', # set the loss function for multiclass classification\n",
        "    'eval_metric': 'merror' # set the evaluation metric for multiclass classification\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_clf = xgb.XGBClassifier(**params)\n",
        "xgb_clf = xgb_clf.fit(train_features, train_labels,\n",
        "                      early_stopping_rounds=20, # stop training if the validation metric does not improve for 10 rounds\n",
        "                      eval_set=[(test_features, test_labels)],\n",
        "                      verbose=False)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = xgb_clf.predict(test_features)\n",
        "\n",
        "y_pred_proba = xgb_clf.predict_proba(test_features)[:,1]\n",
        "\n",
        "result_df, fancy_df = threshold_results(np.linspace(0,1,16,endpoint=True), test_labels, y_pred_proba,average_value='macro')\n",
        "result_df\n"
      ],
      "metadata": {
        "id": "v84A_4haIf9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy"
      ],
      "metadata": {
        "id": "Fll8oiQyJzzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_labels, y_pred)  # Compute accuracy\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "IPiBsUkCJsdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "97LBOmQkJ_g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get the confusion matrix for the test set\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "# Define class labels for the plot\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JDgE3KzvJ3DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run classification prediction on entire site."
      ],
      "metadata": {
        "id": "KCssQbHwKU3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we extract the image features using the"
      ],
      "metadata": {
        "id": "EWqaiz9_KYRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"\""
      ],
      "metadata": {
        "id": "-ykyQf5OKagS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_dict_site = image_feature_site(output_path)"
      ],
      "metadata": {
        "id": "bo4P9itXKkut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we run it on XGBoost and generate a csv file to view it on QGIS"
      ],
      "metadata": {
        "id": "pNooavg_Kp1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array([f[0] for f in features_dict_site.values()])\n",
        "labels = np.array([f[1] for f in features_dict_site.values()])\n",
        "print(np.unique(labels))\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(np.array([f[1] for f in feature_dict.values()]))\n",
        "#['0':'Irregular','2':'Regular','1':'Other']\n",
        "#[0 1 2]\n",
        "\n",
        "print(np.unique(labels))\n",
        "# Evaluate the model on the test data\n",
        "y_pred = xgb_clf.predict(features)\n",
        "\n",
        "\n",
        "\n",
        "print(np.unique(y_pred))\n",
        "\n",
        "# Convert the predicted labels back to their original names\n",
        "predicted_labels = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Print the predicted label names\n",
        "print(np.unique(predicted_labels))\n",
        "\n",
        "y_pred_proba = xgb_clf.predict_proba(features)[:,1]\n",
        "\n",
        "import csv\n",
        "headers = [\"Image Number\", \"Image Address\", \"Predicted Label\"]\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open('output.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the column headers as the first row in the CSV file\n",
        "    writer.writerow(headers)\n",
        "    # Loop through the dictionary and print the image address and predicted label\n",
        "    for i, (img_address, (features, _)) in enumerate(features_dict_site.items()):\n",
        "        predicted_label = label_encoder.classes_[y_pred[i]]\n",
        "        img_filename = img_address.split(\".\")[0] + \".tif\"\n",
        "        row = [(i),img_filename,predicted_label]\n",
        "        writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "ojiNz1leKwQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values of how many images got classified under which label"
      ],
      "metadata": {
        "id": "BzPk6aCmK5U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels, counts = np.unique(y_pred, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Label {label}: {count}\")"
      ],
      "metadata": {
        "id": "xI-z5b7HKylR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}